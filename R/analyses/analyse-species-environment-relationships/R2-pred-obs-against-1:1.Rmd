---
title: Calculating $R^2_{pred-obs}$ against a 1:1 line as opposed to the OLS-fit of $pred \sim $obs$
subtitle: Cape vs SWA publication
author: Ruan van Mazijk
date: '`r Sys.Date()`'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE
)
library(broom)
```

Suppose one regresses $y$ against $x$, and then regresses $\hat{y}$ from that regression against the original data $y$. This new regression between $y$ ($obs$ for simplicity) and $\hat{y}$ ($pred$) values can also be used to generate an $R^2$, though below I demonstrate that this $R^2$ is not of interest.

If $pred$ perfectly matches $obs$, then all values should fall along the 1:1 line.

```{r pred-obs-1-1}
x <- 1:10
obs <- x
m <- lm(obs ~ x)
pred <- m$fitted.values
plot(pred ~ obs)
abline(0, 1, lty = "dashed")
```

The $R^2$ for the above regression will, unsurpisingly be 1.

```{r pred-obs-r2}
m <- lm(pred ~ obs)
glance(m)$r.squared
```

The $R^2$ of a $pred$-$obs$-regression is contingent on the slope of the relationship between model predictions and the observed data. Suppose we have a model that overpredicts for small observed values and underpredicts for large observed values.

```{r pred-obs-r2-slope-gt-1}
obs <- -10:10
pred <- jitter(3 * obs, factor = 10)
m <- lm(pred ~ obs)
plot(pred ~ obs)
abline(m)
abline(0, 1, lty = "dashed")
```

The $R^2$ of this regression (`r glance(m)$r.squared`) does not capture that this model that generates the predicted values ($pred$) is failing to match the data at its extremes.

Instead, we must define an $R^2$-like metric that measures the $R^2$ "about the 1:1 line"---$R^2_{pred-obs}$

The simple $R^2$ for a given OLS regression is defined as the ratio of sums of squares ($SS$) of regression to the total $SS$.

\begin{align}
  R^2
    &= \frac{SS_{regression}}{SS_{total}}
    &= \frac{
      \sum_{i=1}^n (\hat{y_i} - \overline{y})^2
    }{
      \sum_{i=1}^n (y_i - \overline{y})^2
    }
\end{align}

We wish to measure, instead, the degree to which the original model minimises the deviation of predicted values from the 1:1 line.

Traditional $R^2$ describes the "residue" between the null ($\overline{y}$) and the data ($y$) that the fit ($\hat{y}$) has accounted for (first figure below). In a similar sense, the fit (sensu $pred$) can account for residue between the 1:1 line between fit and observed values and a null of those fits ($\overline{pred}$) (seconds figure below).

```{r traditional-r2-logic, echo=FALSE, fig.cap='Logic behind traditional $R^2$.'}
x <- 1:25
y <- jitter(3 * x, 15)
m <- lm(y ~ x)
plot(y ~ x)
abline(h = mean(y))
text(x = 25, y = 30, expression(paste(bar(y))))
abline(m)
text(x = 25, y = 70, expression(paste(hat(y))))
```

```{r r2-pred-obs-logic, echo=FALSE, fig.cap='Logic behind proposed $R^2_{pred-obs}$.'}
obs <- -10:10
pred <- jitter(1.5 * obs, 15)
plot(pred ~ obs, xlim = range(pred))
abline(h = mean(pred))
text(x = 10, y = -2, expression(paste(bar(y))))
abline(0, 1, lty = "dashed")
text(x = 10, y = 8, "1:1")
```

As such, we can define $R^2_{pred-obs}$, analogously to traditional $R^2$, as the ratio between the $SS$ of $pred$ versus $\overline{pred}$ and the $SS$ of the 1:1 line against $\overline{pred}$.

\begin{align}
  obs \equiv the \ 1:1 \ line \\
  R^2_{pred-obs}
    &= \frac{SS_{pred}}{SS_{1:1}} \\
    &= \frac{
      \sum_{i=1}^n (pred_i - \overline{pred})^2
    }{
      \sum_{i=1}^n (obs_i - \overline{pred})^2
    }
\end{align}

```{r}
r2_pred_obs <- function(pred, obs) {
  one_to_one <- obs
  ss_pred <- sum((pred - mean(pred)) ^ 2)
  ss_one_to_one <- sum((one_to_one - mean(pred)) ^ 2)
  r2_pred_obs <- ss_pred / ss_one_to_one
  data.frame(ss_pred, ss_one_to_one, r2_pred_obs)
}
obs <- 1:10
pred <- jitter(3 * obs, 5)
plot(pred ~ obs)
abline(0, 1, lty = "dashed")
r2_pred_obs(pred, obs)
```

***

```{r}
r2_pred_obs <- function(pred, obs) {
  one_to_one <- obs
  ss_one_to_one <- sum((one_to_one - mean(pred)) ^ 2)
  ss_pred_obs_total <- sum((pred - mean(pred)) ^ 2)
  r2_pred_obs <- ss_one_to_one / ss_pred_obs_total
  data.frame(ss_one_to_one, ss_pred_obs_total, r2_pred_obs)
}
obs <- -10:10
pred <- jitter(0.5 * obs, 5)
plot(pred ~ obs)
abline(0, 1, lty = "dashed")
abline(h = mean(pred))
r2_pred_obs(pred, obs)
```

```{r}
obs <- -10:10
slope <- seq(-1, 1, length.out = 100)
dat <- data.frame(slope, r2 = NA)
for (i in 1:nrow(r2)) {
  pred <- slope[i] * obs
  dat$r2[i] <- r2_pred_obs(pred, obs)$r2_pred_obs
}
plot(r2 ~ slope, dat, type = "l")
plot(1, pch = "", xlab = "obs", ylab = "pred", xlim = c(-10, 10), ylim = c(-10, 10))
for (i in 1:nrow(r2)) {
  abline(0, dat$slope[i])
}
```

***

```{r}
x <- 1:100
y <- jitter(5 * x, 100)
m <- lm(y ~ x)
glance(m)
m_res <- lm(m$fitted.values ~ m$model$y)
glance(m_res)
```
